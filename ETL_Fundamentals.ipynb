{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DIO_etl_course.ipynb","provenance":[],"authorship_tag":"ABX9TyPxgkOI9iNcJiO2rzfuR9YW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"F6kaeLG3XfFj"},"source":["# Fundamentos de ETL"]},{"cell_type":"markdown","metadata":{"id":"7Kd473X_Qb9b"},"source":["1) EXTRAÇÃO"]},{"cell_type":"code","metadata":{"id":"x_bPpHFlOh8m"},"source":["import pandas as pd\n","\n","# ler csv, diferenciar os dados que são do tipo date, garantir ordem y-m-d nas datas.\n","df = pd.read_csv('ocorrencia_2010_2020.csv', parse_dates = ['ocorrencia_dia'], dayfirst = True)\n","df\n","\n","# retorno dos tipos de dado existentes em cada coluna\n","df.dtypes\n","\n","# retorno apenas dos meses\n","df.ocorrencia_dia.dt.month\n","\n","# primeiras dez linhas\n","df.head(10)\n","\n","# df.tail(10) --> últimas dez linhas"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K8yqhvX1QktS"},"source":["2) VALIDAÇÃO DA EXTRAÇÃO\n"]},{"cell_type":"code","metadata":{"id":"X3KevwWcQrOc"},"source":["pip install pandera \n","\n","# lib útil pra validação de dados\n","import pandera as pa\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z146PSQ-Leil"},"source":["df = pd.read_csv('ocorrencia_2010_2020.csv', parse_dates = ['ocorrencia_dia'], dayfirst = True)\n","df.head(10)\n","\n","# esquema a ser validado --> identificação de erros\n","schema = pa.DataFrameSchema(\n","    columns = {\n","        'codigo_ocorrencia': pa.Column(pa.Int),\n","        'codigo_ocorrencia2': pa.Column(pa.Int),\n","        'ocorrencia_classificacao': pa.Column(pa.String),\n","        'ocorrencia_cidade': pa.Column(pa.String),\n","        'ocorrencia_uf': pa.Column(pa.String, pa.Check.str_length(2,2)),\n","        'ocorrencia_aerodromo': pa.Column(pa.String),\n","        'ocorrencia_dia': pa.Column(pa.DateTime),\n","        'ocorrencia_hora': pa.Column(pa.String, nullable = True)\n","    }\n",")\n","\n","schema.validate(df)\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v4mDqmSbkga5"},"source":["3) LIMPEZA DE DADOS"]},{"cell_type":"markdown","metadata":{"id":"A3NerUMhxWPu"},"source":["3.1 Fazendo algumas alterações"]},{"cell_type":"code","metadata":{"id":"AlsyUVTikoB-"},"source":["df.loc[0:3]                    # dados das três primeiras linhas\n","df.loc[[10,40]]                # dados das linhas 10 e 40\n","df.loc[:, 'ocorrencia_uf']     # todos os dados da coluna ocorrencia_uf\n","\n","df.codigo_ocorrencia.is_unique     # observar se há repetição de texto/valor\n","\n","# transformar a coluna em índice para a tabela como um todo\n","df.set_index('codigo_ocorrencia', inplace = True)\n","\n","# utilizando codigo_ocorrencia para retornar as infos de uma linha\n","df.loc[40324] \n","\n","# voltar ao indice original\n","df.reset_index(drop = True, inplace = True)\n","df.head()\n","\n","#### alterando dados\n","\n","# deixando vazia a célula com asterisco da primeira linha de ocorrencia_aerodromo\n","df.loc[0,'ocorrencia_aerodromo'] = ''\n","df.head(1)\n","\n","# alterando todos os dados de uma linha\n","df.loc[1] = 20  \n","df.head(2)\n","\n","# alterando todos os dados de uma coluna\n","df.loc[:, 'ocorrencia_dia'] = 10  \n","df.head()\n","\n","# criando coluna de backup de segurança para não perder dados originais!!!\n","df['ocorrencia_uf_bkp'] = df.ocorrencia_uf  \n","df\n","\n","# alterando a classificação dos incidentes\n","# as ocorrencias de SP têm todas a classificação \"GRAVE\"\n","df.loc[df.ocorrencia_uf == 'SP', ['ocorrencia_classificacao']] = 'GRAVE'\n","df.loc[df.ocorrencia_uf == 'SP']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RXfJj-Vywap0"},"source":["# se esse código for rodado, retornará o dataset original, porque as alterações \n","# feitas no bloco anterior dizem respeito apenas ao dataframe\n","df = pd.read_csv('ocorrencia_2010_2020.csv', parse_dates = ['ocorrencia_dia'], dayfirst = True)\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M2tmSgZdxbJT"},"source":["3.2 Limpeza de dados"]},{"cell_type":"code","metadata":{"id":"UQIN_AZsw8jq"},"source":["# agora sim, depois de fazer as modificações desejadas, porém mudando de ideia\n","# e voltando ao dataset original\n","\n","### limpando dados\n","\n","''' Utilizando filtro de excel no csv analisado percebemos que os seguintes dados\n","precisam ser limpados do dataframe:\n","\n","ocorrencia_uf\n","**\n","\n","ocorrencia_aerodromo\n","****\n","*****\n","####\n","####!\n","\n","ocorrencia_hora\n","NULL\n","'''\n","# opção 1 -- alterando de modo específico para <NA>\n","# df.loc[df.'ocorrencia_aerodromo' == '****', ['ocorrencia_aerodromo']] = pd.NA\n","\n","# opção 2 -- alterando no geral\n","df.replace(['**', '****', '*****', '####', '####!', 'NULL'], pd.NA, inplace = True)\n","\n","# saber quantos NA's há no dataframe\n","df.isna().sum()       # ou df.isnull().sum()  \n","\n","# replace os NA's com alguma coisa\n","# atenção à necessidade de usar o \"inplace = True\"\n","df.fillna(0, inplace = True)\n","\n","# replace NA's ou alguma coisa somente em algumas colunas\n","df.fillna(value = {'ocorrencia_classificacao':30}, inplace = True)\n","\n","# exclusão de uma coluna de backup que não terá mais uso\n","# obs. utiliza-se \"axis = 1\" para especificar que se trata da coluna. Isso porque,\n","# por padrão, se nenhum parâmetro for escrito o python considera \"axis = 0\" que \n","# se refere ao eixo horizontal, i.e., às linhas.\n","df['ocorrencia_hora_bkp'] = df.ocorrencia_hora\n","df.drop(['ocorrencia_hora_bkp'],  axis = 1, inplace = True)\n","\n","# remove a LINHA TODA em que um valor nulo se encontrava\n","df.dropna()\n","\n","# remove linhas duplicadas\n","df.drop_duplicates(inplace = True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PRr2Bw2pO5lX"},"source":["4) PARTE FINAL: TRANSFORMAÇÃO\n"]},{"cell_type":"code","metadata":{"id":"mWxy9UjBPB1U"},"source":["import pandas as pd\n","import pandera as pa"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kaibo433Pza9"},"source":["# adicionando na leitura do dataframe (e antes da validação) o trabalho de \n","# limpeza já feito. (Apenas porque nesse caso é possível fazer isso.)\n","\n","valores_ausentes = ['**', '****', '*****', '####', '####!', 'NULL']\n","df = pd.read_csv('ocorrencia_2010_2020.csv', parse_dates = ['ocorrencia_dia'], dayfirst = True, na_values = valores_ausentes)\n","\n","schema = pa.DataFrameSchema(\n","    columns = {\n","        'codigo_ocorrencia': pa.Column(pa.Int),\n","        'codigo_ocorrencia2': pa.Column(pa.Int),\n","        'ocorrencia_classificacao': pa.Column(pa.String),\n","        'ocorrencia_cidade': pa.Column(pa.String),\n","        'ocorrencia_uf': pa.Column(pa.String, pa.Check.str_length(2,2), nullable = True),\n","        'ocorrencia_aerodromo': pa.Column(pa.String, nullable = True),\n","        'ocorrencia_dia': pa.Column(pa.DateTime),\n","        'ocorrencia_hora': pa.Column(pa.String, nullable = True)\n","    }\n",")\n","\n","schema.validate(df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PXeGSsi2U60y"},"source":["# utilização da variavel filtro para facilitar leitura\n","# e localização de infos\n","# ex. localizando células com valor nulo\n","filtro = df.ocorrencia_uf.is_null()\n","df.loc[filtro]\n","\n","filtro = df.ocorrencia_aerodromo.is_null()\n","df.loc[filtro]\n","\n","# count por default não conta células nulas\n","df.count()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EXy4KBS2RWz_"},"source":["### aprimorando filtros\n","\n","# ocorrências no rio de janeiro + nome das cidades\n","filtro = df.ocorrencia_uf == 'RJ'\n","df.loc[filtro, ['ocorrencia_uf', 'ocorrencia_cidade']]\n","\n","# todas as infos sobre ocorrências graves\n","filtro = df.ocorrencia_classificacao == 'INCIDENTE GRAVE'\n","df.loc[filtro]\n","\n","# ocorrências graves no estado de Minas Gerais\n","filtro1 = df.ocorrencia_classificacao == 'INCIDENTE GRAVE'\n","filtro2 = df.ocorrencia_uf == 'MG'\n","df.loc[filtro1 & filtro2]\n","\n","# ocorrências graves OU no estado do Amazonas\n","filtro1 = df.ocorrencia_classificacao == 'INCIDENTE GRAVE'\n","filtro2 = df.ocorrencia_uf == 'AM'\n","df.loc[filtro1 | filtro2]\n","\n","# ((ocorrências graves) ou (ocorrências comuns)) no estado de Goiás\n","filtro1 = (df.ocorrencia_classificacao == 'INCIDENTE GRAVE') | (df.ocorrencia_classificacao == 'INCIDENTE')\n","filtro2 = df.ocorrencia_uf == 'GO'\n","df.loc[filtro1 & filtro2]\n","\n","'''forma mais simples de fazer o código acima com .isin:\n","\n","# ((ocorrências graves) ou (ocorrências comuns)) no estado de Goiás\n","filtro1 = (df.ocorrencia_classificacao.isin == (['INCIDENTE GRAVE', 'INCIDENTE'])\n","filtro2 = df.ocorrencia_uf == 'GO'\n","df.loc[filtro1 & filtro2]\n","'''\n","\n","# análise parcial\n","# ex. todas as ocorrências cuja cidade começa com C\n","filtro = df.ocorrencia_cidade.str[0] == 'C'\n","df.loc[filtro, 'codigo_ocorrencia']\n","\n","# ex. todas as ocorrências cuja cidade termina com 'MA'\n","filtro = df.ocorrencia_cidade.str[-2:] == 'MA'\n","df.loc[filtro, 'codigo_ocorrencia']\n","\n","# ex. todas as ocorrências cuja uf CONTÉM 'S' (em qualquer posição)\n","filtro = df.ocorrencia_uf.str.contains('S')\n","df.loc[filtro]\n","\n","# ex. todas as ocorrências cuja cidade CONTÉM 'S' ou 'PA' (em qualquer posição)\n","filtro = df.ocorrencia_uf.str.contains('S | PA')\n","df.loc[filtro]\n","\n","# ocorrencias de 2015\n","# ocorrencia_dia é do tipo DateTime\n","filtro = df.ocorrencia_dia.dt.year == 2015\n","df.loc[filtro] \n","\n","# ocorrencias de dezembro de 2016\n","filtro1 = df.ocorrencia_dia.dt.year == 2016\n","filtro2 = df.ocorrencia_dia.dt.month == 12\n","df.loc[filtro1 & filtro2]\n","\n","''' forma mais compacta do código acima:\n","\n","# ocorrencias de dezembro de 2016\n","filtro1 = (df.ocorrencia_dia.dt.year == 2016) & (df.ocorrencia_dia.dt.month == 12)\n","df.loc[filtro]\n","'''\n","# ocorrencias de dezembro de 2016 com código iniciando em 5\n","filtro1 = df.ocorrencia_dia.dt.year == 2016\n","filtro2 = df.ocorrencia_dia.dt.month == 12\n","filtro3 = df.ocorrencia_codigo.str[0] == '5'\n","df.loc[filtro1 & filtro2 & filtro3]\n","\n","# ocorrencias de julho de 2014 entre os dias 5 e 10\n","filtroAno = df.ocorrencia_dia.dt.year == 2014\n","filtroMes = df.ocorrencia_dia.dt.month == 7\n","filtroDia = (df.ocorrencia_dia.dt.day > 4) & (df.ocorrencia_dia.dt.day < 11)\n","df.loc[filtroAno & filtroMes & filtroDia]\n","\n","# ocorrencias de julho de 2014 entre meia noite do dia 5 e 10h da manhã do dia 7\n","\n","# unindo as colunas de data e horário \n","# utilizando astype para não dar erro nos tipos de dado e utilizando to_datetime\n","# para que tenhas células com datetime, não com strings\n","df['ocorrencia_dia_hora'] = pd.to_datime(df.ocorrencia_dia.astype(str) + '' + df.ocorrencia_hora)\n","\n","filtro1 = df.ocorrencia_dia_hora >= '2014-07-05 00:00:00'\n","filtro2 = df.ocorrencia_dia_hora <= '2014-07-07 10:00:00'\n","df.loc[filtro1 & filtro2]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_0aiVXL2L-FI"},"source":["# agrupamento, como fazer\n","\n","# atribuindo filtros a um novo dataframe --> informações sobre março de 2010\n","filtro1 = df.ocorrencia_dia.dt.year == 2010\n","filtro2 = df.ocorrencia_dia.dt.month == 3\n","df201503 = df.loc[filtro1 & filtro2]\n","df201503\n","\n","df201503.count()\n","# agrupando a partir de uma coluna e contando a partir de outra que não tenha dados nulos\n","df201503.groupby(['codigo_ocorrencia']).ocorrencia_hora.count()\n","\n","# outra opção -- utilizar size() para agrupar e contar as linhas que foram agrupadas\n","df201503.groupby(['codigo_ocorrencia']).size()\n","\n","\n","df201503.groupby(['ocorrencia_classificacao']).size().sort_values()                    # ordem crescente\n","df201503.groupby(['ocorrencia_classificacao']).size().sort_values(ascending = False)   # ordem decrescente\n","\n","######\n","# EX. agrupamento da região sudeste no ano de 2011\n","filtro1 = df.ocorrencia_dia.dt.year == 2011\n","filtro2 = df.ocorrencia_uf.isin(['SP', 'RJ', 'MG', 'ES'])\n","dfsudeste2011 = df.loc[filtro1 & filtro2] \n","dfsudeste2011\n","\n","# agrupando por tipo de ocorrência, descobrimos a quantidade de incidentes no \n","# sudeste em 2011 e quantos de cada tipo\n","dfsudeste2011.groupyby(['ocorrencia_classificacao']).size()\n","\n","# agrupando por tipo de ocorrência e depois por uf para saber a quantidade de cada tipo\n","# de incidente\n","dfsudeste2011.groupyby(['ocorrencia_classificacao', 'ocorrencia_uf']).size()\n","\n","# agrupando por uf e depois por tipo de ocorrência para saber a quantidade de cada tipo\n","# de incidente\n","dfsudeste2011.groupyby(['ocorrencia_uf', 'ocorrencia_classificacao']).size()\n","\n","# filtrando as ocorrência identificadas na cidade do Rio de Janeiro\n","filtro = dfsudeste2011.ocorrencia_cidade == 'RIO DE JANEIRO'\n","dfsudeste2011.loc[filtro]\n","\n","# agrupando o total de recomendações por mês e por cidade\n","filtro = dfsudeste.total_recomendacoes > 0\n","dfsudeste2011.loc[filtro].groupby(['ocorrencia_cidade', dfsudeste2011.ocorrencia_dia.dt.month]).total_recomendacoes.sum()"],"execution_count":null,"outputs":[]}]}